<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>NLP on Inderjit Singh Chahal</title><link>https://inderjit.in/tags/nlp/</link><description>Recent content in NLP on Inderjit Singh Chahal</description><generator>Hugo -- gohugo.io</generator><managingEditor>chahalinder0007.gmail.com (Inderjit Singh Chahal)</managingEditor><webMaster>chahalinder0007.gmail.com (Inderjit Singh Chahal)</webMaster><lastBuildDate>Thu, 08 Oct 2020 11:00:01 +0530</lastBuildDate><atom:link href="https://inderjit.in/tags/nlp/index.xml" rel="self" type="application/rss+xml"/><item><title>Pattern Exploiting Training for NLP</title><link>https://inderjit.in/post/pet_for_nlp/</link><pubDate>Thu, 08 Oct 2020 11:00:01 +0530</pubDate><author>chahalinder0007.gmail.com (Inderjit Singh Chahal)</author><guid>https://inderjit.in/post/pet_for_nlp/</guid><description>GPT-3 created quite a buzz when it was first launched a couple of months back for its ability to generate great good amount of text to create a more realistic feel, but it suffered from one particular shortcoming that its simply too big. There has been an increasing move towards creating more light weight implementations in NLP,CV and othe areas for machine learning and artificial intelligence, evident from the fact that most of the papers now along with accuracy also feature inference times for the respective model, a good sign of end use awareness in research.</description></item></channel></rss>